<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
<!-- OneTrust Cookies Consent Notice start for xilinx.github.io -->

<script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="03af8d57-0a04-47a6-8f10-322fa00d8fc7" ></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice end for xilinx.github.io -->
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-C0002">(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-5RHQV7');</script>
<!-- End Google Tag Manager -->
  <title>Supporting Deep Learning Models &mdash; Vitis Video Analytics SDK (VVAS) for Data Center 1.0 documentation</title>
      <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="_static/graphviz.css" type="text/css" />
      <link rel="stylesheet" href="_static/custom.css" type="text/css" />
      <link rel="stylesheet" href="_static/_static/custom.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Device Management &amp; Utility tool" href="card_management.html" />
    <link rel="prev" title="Build and install from the VVAS source" href="vvas_build.html" /> 
</head>

<body class="wy-body-for-nav">

<!-- Google Tag Manager -->
<noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-5RHQV7" height="0" width="0" style="display:none;visibility:hidden" class="optanon-category-C0002"></iframe></noscript>
<!-- End Google Tag Manager --> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
            <a href="index.html" class="icon icon-home"> Vitis Video Analytics SDK (VVAS) for Data Center
            <img src="_static/xilinx-header-logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="system_requirements.html">Software &amp; Hardware Requirements</a></li>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="getting_started_tutorial.html">Quickstart Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="features_and_capabilities.html">Features and Capabilities</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">VVAS GStreamer Interface</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="common/gstreamer_plugins/common_plugins.html">GStreamer Plug-ins</a></li>
<li class="toctree-l1"><a class="reference internal" href="common/meta_data/vvas_meta_data_structures.html">VVAS Meta Data Structures</a></li>
<li class="toctree-l1"><a class="reference internal" href="common/for_developers.html">Development Guide</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">VVAS Core API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="api_reference.html">VVAS C API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_guide.html">VVAS C API Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="api_examples.html">VVAS C API Samples</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional Information</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="vvas_build.html">Build and install from the VVAS source</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Supporting Deep Learning Models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#vitis-ai-library-classes-natively-supported-by-vvas">Vitis AI Library classes natively supported by VVAS</a></li>
<li class="toctree-l2"><a class="reference internal" href="#v70-and-vvas-supported-model">V70 and VVAS Supported Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#integrating-dl-models">Integrating DL Models</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#models-natively-supported-by-vvas-xinfer-plugin">1. Models natively supported by vvas_xinfer plugin</a></li>
<li class="toctree-l3"><a class="reference internal" href="#models-not-supported-by-vvas-xinfer-plugin">2. Models not supported by vvas_xinfer plugin</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="card_management.html">Device Management &amp; Utility tool</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: black" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Vitis Video Analytics SDK (VVAS) for Data Center</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Supporting Deep Learning Models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/adding_models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="section" id="supporting-deep-learning-models">
<h1>Supporting Deep Learning Models<a class="headerlink" href="#supporting-deep-learning-models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="vitis-ai-library-classes-natively-supported-by-vvas">
<h2>Vitis AI Library classes natively supported by VVAS<a class="headerlink" href="#vitis-ai-library-classes-natively-supported-by-vvas" title="Permalink to this headline">¶</a></h2>
<p>The VVAS inference plugin, <code class="docutils literal notranslate"><span class="pre">vvas_xinfer</span></code> is designed run inference with the models supported by Vitis AI Library.</p>
<p>Currently <code class="docutils literal notranslate"><span class="pre">vvas_xinfer</span></code> supports most common Vitis AI Library model classes. These supported model classes are mapped to one of the <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">VvasClass</span></code> type in VVAS source  <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/common/vvas_core/vvas_dpucommon.h">vvas_dpucommon.h</a>.</p>
<p>Here is a current list of Vitis AI Library model classes and their corresponding <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">VvasClass</span></code> type. The models belong to these classes are natively supported by the <code class="docutils literal notranslate"><span class="pre">vvas_xinfer</span></code> plugin.</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Library model class</p></th>
<th class="head"><p>VvasClass</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Classification</p></td>
<td><p>VVAS_XCLASS_CLASSIFICATION</p></td>
</tr>
<tr class="row-odd"><td><p>Face Detection</p></td>
<td><p>VVAS_XCLASS_FACEDETECT</p></td>
</tr>
<tr class="row-even"><td><p>Face Landmark Detection</p></td>
<td><p>VVAS_XCLASS_FACELANDMARK</p></td>
</tr>
<tr class="row-odd"><td><p>SSD Detection</p></td>
<td><p>VVAS_XCLASS_SSD</p></td>
</tr>
<tr class="row-even"><td><p>SSD Detection (Tensorflow)</p></td>
<td><p>VVAS_XCLASS_TFSSD</p></td>
</tr>
<tr class="row-odd"><td><p>Pose Detection</p></td>
<td><p>VVAS_XCLASS_POSEDETECT</p></td>
</tr>
<tr class="row-even"><td><p>Semantic Segmentation</p></td>
<td><p>VVAS_XCLASS_SEGMENTATION</p></td>
</tr>
<tr class="row-odd"><td><p>Road Line Detection</p></td>
<td><p>VVAS_XCLASS_ROADLINE</p></td>
</tr>
<tr class="row-even"><td><p>YOLOv3 Detection</p></td>
<td><p>VVAS_XCLASS_YOLOV3</p></td>
</tr>
<tr class="row-odd"><td><p>YOLOv2 Detection</p></td>
<td><p>VVAS_XCLASS_YOLOV2</p></td>
</tr>
<tr class="row-even"><td><p>RefineDet Detection</p></td>
<td><p>VVAS_XCLASS_REFINEDET</p></td>
</tr>
<tr class="row-odd"><td><p>ReID Detection</p></td>
<td><p>VVAS_XCLASS_REID</p></td>
</tr>
<tr class="row-even"><td><p>Face Recognition</p></td>
<td><p>VVAS_XCLASS_FACEFEATURE</p></td>
</tr>
<tr class="row-odd"><td><p>Plate Detection</p></td>
<td><p>VVAS_XCLASS_PLATEDETECT</p></td>
</tr>
<tr class="row-even"><td><p>Plate Recognition</p></td>
<td><p>VVAS_XCLASS_PLATENUM</p></td>
</tr>
<tr class="row-odd"><td><p>Bayesian Crowd Counting</p></td>
<td><p>VVAS_XCLASS_BCC</p></td>
</tr>
<tr class="row-even"><td><p>UltraFast Road Line Detection</p></td>
<td><p>VVAS_XCLASS_ULTRAFAST</p></td>
</tr>
<tr class="row-odd"><td><p>Vehicle Classification</p></td>
<td><p>VVAS_XCLASS_VEHICLECLASSIFICATION</p></td>
</tr>
<tr class="row-even"><td><p>EfficientDet_D2</p></td>
<td><p>VVAS_XCLASS_EFFICIENTDETD2</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="v70-and-vvas-supported-model">
<h2>V70 and VVAS Supported Model<a class="headerlink" href="#v70-and-vvas-supported-model" title="Permalink to this headline">¶</a></h2>
<p>Currently all the V70 supported models from the Vitis AI Model Zoo are available in  <a class="reference external" href="https://www.xilinx.com/bin/public/openDownload?filename=xilinx_model_zoo_v70_patch.tar.gz">this link</a>. These models are saved in their DPU deployable state, that means these models are already compiled and compiled model artifacts are saved in their respective model directory.</p>
<p>The current release has been validated with the below models with VVAS on V70 platform</p>
<table class="colwidths-given docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head"><p>VVAS Model Class</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>face_mask_detection_pt</p></td>
<td><p>YOLOV3</p></td>
</tr>
<tr class="row-odd"><td><p>SemanticFPN_cityscapes_pt</p></td>
<td><p>SEGMENTATION</p></td>
</tr>
<tr class="row-even"><td><p>SemanticFPN_Mobilenetv2_pt</p></td>
<td><p>SEGMENTATION</p></td>
</tr>
<tr class="row-odd"><td><p>semantic_seg_citys_tf2</p></td>
<td><p>SEGMENTATION</p></td>
</tr>
<tr class="row-even"><td><p>ssd_inception_v2_coco_tf</p></td>
<td><p>TFSSD</p></td>
</tr>
<tr class="row-odd"><td><p>ssdlite_mobilenet_v2_coco_tf</p></td>
<td><p>TFSSD</p></td>
</tr>
<tr class="row-even"><td><p>ssd_mobilenet_v1_coco_tf</p></td>
<td><p>TFSSD</p></td>
</tr>
<tr class="row-odd"><td><p>ssd_mobilenet_v2_coco_tf</p></td>
<td><p>TFSSD</p></td>
</tr>
<tr class="row-even"><td><p>ssd_resnet_50_fpn_coco_tf</p></td>
<td><p>TFSSD</p></td>
</tr>
<tr class="row-odd"><td><p>yolov3_coco_416_tf2</p></td>
<td><p>YOLOV3</p></td>
</tr>
<tr class="row-even"><td><p>YOLOV3_VOC</p></td>
<td><p>YOLOV3</p></td>
</tr>
<tr class="row-odd"><td><p>efficientnet_lite_tf2</p></td>
<td><p>CLASSIFICATION</p></td>
</tr>
<tr class="row-even"><td><p>chen_color_resnet18_pt</p></td>
<td><p>CLASSIFICATION</p></td>
</tr>
<tr class="row-odd"><td><p>vehicle_make_resnet18_pt</p></td>
<td><p>VEHICLECLASSIFICATION</p></td>
</tr>
<tr class="row-even"><td><p>vehicle_type_resnet18_pt</p></td>
<td><p>VEHICLECLASSIFICATION</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="integrating-dl-models">
<h2>Integrating DL Models<a class="headerlink" href="#integrating-dl-models" title="Permalink to this headline">¶</a></h2>
<p>There are few different ways to integrate these models in VVAS flow.</p>
<div class="section" id="models-natively-supported-by-vvas-xinfer-plugin">
<h3>1. Models natively supported by vvas_xinfer plugin<a class="headerlink" href="#models-natively-supported-by-vvas-xinfer-plugin" title="Permalink to this headline">¶</a></h3>
<p>The V70 supported models which are supported by one of the <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">VvasClass</span></code> (as shown in the above table) can be enabled in VVAS flow very easily.</p>
<ol class="arabic simple">
<li><p>Download the compiled model directory</p></li>
<li><p>Copy the model directory inside the VVAS docker container to the path <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;</span></code></p>
<ul class="simple">
<li><p>Additionally for the object detection based models, create a <code class="docutils literal notranslate"><span class="pre">label.json</span></code> file and place it inside <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;/</span></code> directory.</p></li>
</ul>
</li>
<li><p>Update <code class="docutils literal notranslate"><span class="pre">infer-config</span></code> configuration JSON file for <code class="docutils literal notranslate"><span class="pre">vvas_xinfer</span></code> plugin to specify the model attributes such as <code class="docutils literal notranslate"><span class="pre">model-name</span></code>, <code class="docutils literal notranslate"><span class="pre">model-class</span></code>, <code class="docutils literal notranslate"><span class="pre">model-format</span></code>, etc.</p></li>
</ol>
</div>
<div class="section" id="models-not-supported-by-vvas-xinfer-plugin">
<h3>2. Models not supported by vvas_xinfer plugin<a class="headerlink" href="#models-not-supported-by-vvas-xinfer-plugin" title="Permalink to this headline">¶</a></h3>
<p>The V70 supported models which are not supported by one of the <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">VvasClass</span></code> (as shown in the above table) can be enabled in VVAS flow in a couple of ways based on your preference.</p>
<ul class="simple">
<li><p>Method 1: Add support of the model through Vitis AI Library. This requires the change in the VVAS codebase to use Vitis AI Library API. The advantage of this method is that the user can use higher level Vitis AI Library API which leverage post-processing by the Vitis AI Library directly.</p></li>
<li><p>Method 2: Add support of the model without using Vitis AI Library rather through a special class <code class="docutils literal notranslate"><span class="pre">RAWTENSOR</span></code>. The advantage of this method is that user can implement their own post-processing inside VVAS codebase.</p></li>
</ul>
<p><strong>Method 1: Adding model support through Vitis AI Library</strong></p>
<p>The VVAS Codebase requires the following changes to enable a model support through Vitis AI Library.</p>
<ol class="arabic">
<li><p>Download the compiled model directory</p></li>
<li><p>Copy the model directory inside the VVAS docker container in the path <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>Additionally for the object detection based models, create a <code class="docutils literal notranslate"><span class="pre">label.json</span></code> file and place it inside <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;/</span></code> directory.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Create the new model class type in the file  <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/common/vvas_core/vvas_dpucommon.h">vvas_dpucommon.h</a>.</p></li>
<li><p>Create implementation files (.cpp and .hpp file) for the new class inside the directory <code class="docutils literal notranslate"><span class="pre">vvas/vvas-core/dpuinfer</span></code>. You may refer to the existing model class implemetation files for the reference.</p></li>
</ol>
<p>For example the implementation code files for <code class="docutils literal notranslate"><span class="pre">VVAS_XCLASS_SEGMENTATION</span></code> class are:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/vvas_segmentation.hpp">vvas_segmentation.hpp</a></p></li>
<li><p><a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/vvas_segmentation.cpp">vvas_segmentation.cpp</a></p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Include the implemtation header file inside <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/vvas_dpuinfer.cpp#L67">vvas_dpuinfer.cpp</a></p></li>
</ol>
<p>For example, the implementation header file <code class="docutils literal notranslate"><span class="pre">vvas_segmentation.hpp</span></code> for <code class="docutils literal notranslate"><span class="pre">VVAS_XCLASS_SEGMENTATION</span></code> is included inside <code class="docutils literal notranslate"><span class="pre">vvas_dpuinfer.cpp</span></code></p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#ifdef ENABLE_SEGMENTATION</span>
<span class="cp">#include</span><span class="w"> </span><span class="cpf">&quot;vvas_segmentation.hpp&quot;</span><span class="cp"></span>
<span class="cp">#endif</span>
</pre></div>
</div>
<ol class="arabic simple" start="6">
<li><p>Create the model inside <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/vvas_dpuinfer.cpp#L478">vvas_dpuinfer.cpp</a></p></li>
</ol>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="cp">#ifdef ENABLE_SEGMENTATION</span>
<span class="k">case</span><span class="w"> </span><span class="no">VVAS_XCLASS_SEGMENTATION</span><span class="p">:</span><span class="w"></span>
<span class="p">{</span><span class="w"></span>
<span class="w">  </span><span class="n">model</span><span class="w"> </span><span class="o">=</span><span class="w"></span>
<span class="w">      </span><span class="n">new</span><span class="w"> </span><span class="n">vvas_segmentation</span><span class="w"> </span><span class="p">(</span><span class="n">kpriv</span><span class="p">,</span><span class="w"> </span><span class="n">kpriv</span><span class="o">-&gt;</span><span class="n">elfname</span><span class="p">,</span><span class="w"> </span><span class="n">kpriv</span><span class="o">-&gt;</span><span class="n">need_preprocess</span><span class="p">);</span><span class="w"></span>
<span class="w">  </span><span class="k">break</span><span class="p">;</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
<span class="cp">#endif</span>
</pre></div>
</div>
<ol class="arabic simple" start="7">
<li><p>Update <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/vvas_dpumodels.hpp#L34">vvas_dpumodels.hpp</a></p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="o">[</span>VVAS_XCLASS_SEGMENTATION<span class="o">]</span> <span class="o">=</span> <span class="s2">&quot;SEGMENTATION&quot;</span>,
</pre></div>
</div>
<ol class="arabic simple" start="8">
<li><p>Update <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/dpuinfer/meson.build">vvas-core/dpuinfer/meson.build</a>  for the new class and corresponding Vitis AI library name</p></li>
</ol>
<p>Example with respect to the same  <code class="docutils literal notranslate"><span class="pre">VVAS_XCLASS_SEGMENTATION</span></code> class</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1">#ADD SEGMENTATION</span>
<span class="k">if</span> get_option<span class="o">(</span><span class="s1">&#39;SEGMENTATION&#39;</span><span class="o">)</span> !<span class="o">=</span> <span class="s1">&#39;0&#39;</span>
  <span class="nv">segmentation_dep</span> <span class="o">=</span> cc.find_library<span class="o">(</span><span class="s1">&#39;vitis_ai_library-segmentation&#39;</span><span class="o">)</span>
  <span class="nv">dpuinfer_sources</span> <span class="o">+=</span> <span class="o">[</span>
      <span class="s1">&#39;vvas_segmentation.cpp&#39;</span>,
  <span class="o">]</span>
<span class="k">else</span>
  <span class="nv">segmentation_dep</span> <span class="o">=</span> <span class="o">[]</span>
endif

.....
.....
dependencies : <span class="o">[</span>xrt_dep, core_common_dep,...., segmentation_dep,...<span class="o">]</span>,
</pre></div>
</div>
<ol class="arabic simple" start="9">
<li><p>Update top-level <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/meson.build">meson.build</a> file</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> get_option<span class="o">(</span><span class="s1">&#39;SEGMENTATION&#39;</span><span class="o">)</span> !<span class="o">=</span> <span class="s1">&#39;0&#39;</span>
add_project_arguments<span class="o">(</span><span class="s1">&#39;-DENABLE_SEGMENTATION&#39;</span>, language : <span class="s1">&#39;c&#39;</span><span class="o">)</span>
add_project_arguments<span class="o">(</span><span class="s1">&#39;-DENABLE_SEGMENTATION&#39;</span>, language : <span class="s1">&#39;cpp&#39;</span><span class="o">)</span>
endif
</pre></div>
</div>
<ol class="arabic simple" start="10">
<li><p>Update <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/meson_options.txt">meson_options.txt</a> file</p></li>
</ol>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>option<span class="o">(</span><span class="s1">&#39;SEGMENTATION&#39;</span>, type: <span class="s1">&#39;string&#39;</span>, value: <span class="s1">&#39;1&#39;</span>,
     description: <span class="s1">&#39;Enable disable SEGMENTATION models&#39;</span><span class="o">)</span>
</pre></div>
</div>
<ol class="arabic simple" start="11">
<li><p>In case the new model results are not supported by the existing fields in the VVAS Inference Metadata structure, then it is required to add support of the new inference metadata inside the <code class="docutils literal notranslate"><span class="pre">struct</span> <span class="pre">VvasInferPrediction</span></code> which is defined inside <a class="reference external" href="https://github.com/Xilinx/vvas-core/blob/master/common/vvas_core/vvas_infer_prediction.h">vvas_infer_prediction.h</a>.</p></li>
</ol>
<p><strong>Method 2: Adding model support through the ``RAWTENSOR`` class</strong></p>
<p>The unsupported model can also be supported through a special class <code class="docutils literal notranslate"><span class="pre">RAWTENSOR</span></code>. This <code class="docutils literal notranslate"><span class="pre">RAWTENSOR</span></code> class in registered inside <code class="docutils literal notranslate"><span class="pre">enum</span> <span class="pre">VvasClass</span></code> as <code class="docutils literal notranslate"><span class="pre">VVAS_XCLASS_RAWTENSOR</span></code>.</p>
<ol class="arabic">
<li><p>Download the compiled model directory</p></li>
<li><p>Copy the model directory inside the VVAS docker container in the path <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;</span></code></p>
<blockquote>
<div><ul class="simple">
<li><p>Additionally for the object detection based models, create a <code class="docutils literal notranslate"><span class="pre">label.json</span></code> file and place it inside <code class="docutils literal notranslate"><span class="pre">/usr/share/vitis_ai_library/models/&lt;model_name&gt;/</span></code> directory.</p></li>
</ul>
</div></blockquote>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">infer-json</span></code> file as below has to be modified by changing the <code class="docutils literal notranslate"><span class="pre">model-class</span></code> to <code class="docutils literal notranslate"><span class="pre">RAWTENSOR</span></code>. Also, as in this case <code class="docutils literal notranslate"><span class="pre">vvas_xinfer</span></code> works on the raw tensor instead of through VAI library, the post-processing inference result is not available directly. Hence it may require to perform proper post-processing after the inference inside the VVAS code base.</p></li>
</ol>
<p>Note the changes inside the <code class="docutils literal notranslate"><span class="pre">infer-config</span></code> JSON file below</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="w"></span>
<span class="w">   </span><span class="nt">&quot;inference-level&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="nt">&quot;attach-ppe-outbuf&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"></span>
<span class="w">   </span><span class="nt">&quot;kernel&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">      </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;batch-size&quot;</span><span class="p">:</span><span class="mi">14</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;model-name&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;yolov3_voc_tf&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;model-class&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;RAWTENSOR&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;model-format&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BGR&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;model-path&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/usr/share/vitis_ai_library/models/&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;postprocess-lib-path&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;/opt/xilinx/vvas/lib/libvvascore_postprocessor.so&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;postprocess-function&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;vvas_postprocess_tensor&quot;</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;performance-test&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="kc">false</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;vitis-ai-preprocess&quot;</span><span class="p">:</span><span class="kc">false</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;debug-level&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;max-objects&quot;</span><span class="p">:</span><span class="mi">3</span><span class="p">,</span><span class="w"></span>
<span class="w">         </span><span class="nt">&quot;filter-labels&quot;</span><span class="p">:[</span><span class="s2">&quot;car&quot;</span><span class="p">]</span><span class="w"></span>
<span class="w">      </span><span class="p">}</span><span class="w"></span>
<span class="w">   </span><span class="p">}</span><span class="w"></span>
<span class="p">}</span><span class="w"></span>
</pre></div>
</div>
<p>The special configurations in the above <code class="docutils literal notranslate"><span class="pre">infer-config</span></code> JSON file</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">model-class</span></code> specified to <code class="docutils literal notranslate"><span class="pre">RAWTENSOR</span></code></p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">postprocess-lib-path</span></code> is specified to a sample VVAS post-processing library <code class="docutils literal notranslate"><span class="pre">libvvascore_postprocessor.so</span></code>.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">postprocess-function</span></code> is specified to post-processing function <code class="docutils literal notranslate"><span class="pre">vvas_postprocess_tensor</span></code></p></li>
</ol>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The post-processing library shown above <code class="docutils literal notranslate"><span class="pre">libvvascore_postprocessor.so</span></code> should only be used as a reference, as it does not support post-processing requirements for all the different types of models.</p>
</div>
</div>
</div>
</div>


           </div>
          </div>
          
                  <style>
                        .footer {
                        position: fixed;
                        left: 0;
                        bottom: 0;
                        width: 100%;
                        }
                  </style>
				  
				  <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="vvas_build.html" class="btn btn-neutral float-left" title="Build and install from the VVAS source" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="card_management.html" class="btn btn-neutral float-right" title="Device Management &amp; Utility tool" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Advanced Micro Devices, Inc.
      <span class="lastupdated">Last updated on October 7, 2022.
      </span></p>
  </div>



										<div class="aem-Grid aem-Grid--16">
											<div class="aem-GridColumn aem-GridColumn--xxxlarge--none aem-GridColumn--xsmall--16 aem-GridColumn--offset--xsmall--0 aem-GridColumn--xlarge--none aem-GridColumn--xxlarge--none aem-GridColumn--default--none aem-GridColumn--offset--large--1 aem-GridColumn--xlarge--12 aem-GridColumn--offset--default--0 aem-GridColumn--xxlarge--10 aem-GridColumn--offset--xlarge--2 aem-GridColumn--offset--xxlarge--3 aem-GridColumn--offset--xxxlarge--4 aem-GridColumn--xsmall--none aem-GridColumn--large--none aem-GridColumn aem-GridColumn--large--14 aem-GridColumn--xxxlarge--8 aem-GridColumn--default--16">
												<div class="container-fluid sub-footer">

													                    <div class="row">
                        <div class="col-xs-24">
                          <p><a target="_blank" href="https://www.amd.com/en/corporate/copyright">Terms and Conditions</a> | <a target="_blank" href="https://www.amd.com/en/corporate/privacy">Privacy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/cookies">Cookie Policy</a> | <a target="_blank" href="https://www.amd.com/en/corporate/trademarks">Trademarks</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf">Statement on Forced Labor</a> | <a target="_blank" href="https://www.amd.com/en/corporate/competition">Fair and Open Competition</a> | <a target="_blank" href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf">UK Tax Strategy</a> | <a target="_blank" href="https://docs.xilinx.com/v/u/9x6YvZKuWyhJId7y7RQQKA">Inclusive Terminology</a> | <a href="#cookiessettings" class="ot-sdk-show-settings">Cookies Settings</a></p>
                        </div>
                    </div>
												</div>
											</div>
										</div>
										
</br>


  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 <script type="text/javascript">
    $(document).ready(function() {
        $(".toggle > *").hide();
        $(".toggle .header").show();
        $(".toggle .header").click(function() {
            $(this).parent().children().not(".header").toggle(400);
            $(this).parent().children(".header").toggleClass("open");
        })
    });
</script>


</body>
</html>